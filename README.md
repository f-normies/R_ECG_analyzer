# Обзор
`R_ECG_analyzer` предназначен для анализа данных ЭКГ с целью классификации различных медицинских диагнозов. Проект использует ЯП R и применяет для анализа алгоритм Naive Bayes.

# Медицинские диагнозы
Проект направлен на классификацию следующих диагнозов по данным ЭКГ:
* Венозная дисциркуляторная энцефалопатия (ВДЭ) - Y1
* Желчекаменная болезнь (ЖКЭ) - Y2
* Ишемическая болезнь (ИБЭ) - Y3
* Узловой зоб щитовидной железы (УЩЭ) - Y4
* Язвенная болезнь (ЯБЭ) - Y5
* Норма - N

# Выборка
Выборка состоит из множества строк, где каждая строка представляет собой образец ЭКГ-данных. В выборке имеются следующие столбцы:
* `class`: Этот столбец представляет собой диагноз образца ЭКГ. 
* `V2 - V217`: В этих столбцах представлены кодограммы векторов ЭКГ. Каждый столбец содержит числовое значение, представляющее встречаемость данного вектора во всем сигнале ЭКГ.

# Bayes.R
## Использованные пакеты
* `readr`: Пакет используется для чтения данных из различных форматов в R.
* `caret`: Пакет для обучения и построения классификационных и регрессионных моделей.
* `e1071`: Пакет, предоставляющий функции для статистики и теории вероятностей в R, особенно для классификатора Naive Bayes.
* `pROC`: Пакет для визуализации и анализа кривых приемных операционных характеристик (ROC).

## Документация
* split_data: Эта функция предназначена для разбиения всей выборки на обучающий, проверочный и тестовый наборы данных. Она принимает на вход всю выборку и возвращает список, содержащий три подмножества.

Данные загружаются из файла `Common dataset.txt`, содержащий всю выборку. Далее, данные в колонках V2 - V217 масштабируются при помощи встроенной функции `scale`. 

Для каждого уникального класса в выборке (за исключением класса "N") данные преобразуются в бинарный формат. Это означает, что для каждого класса выборки, который не является классом "N", будут образовываться подвыборки с этим классом и классом "N". Данное преобразование необходимо, поскольку при анализе данных было замечено, что некоторые образцы различных классов неразделимы между собой.

Далее, применяется функция `split_data`.

Для каждой бинарной подвыборки обучается модель Naive Bayes с помощью функции naiveBayes из библиотеки e1071. Модели хранятся в списке models.

Обученные модели Naive Bayes тестируются на соответствующих тестовых наборах. Для визуализации эффективности моделей используются ROC-кривые. Точность каждой модели рассчитывается путем сравнения предсказанных классов с реальными классами в тестовом наборе. Точность выводится в процентах.

# Результаты
* Классификатор Y3 - самый лучший классификатор с точностью 93,18%, за ним следует Y2 с 92,96%.
* Классификаторы Y4 и Y5 имеют умеренную точность - 86,62% и 81,08% соответственно.
* Наименее эффективным классификатором является Y1, точность которого составляет 79,10%.

Также, для оценки соотношения чувствительности (частота истинных положительных результатов) и специфичности (1 - частота ложных положительных результатов) используются ROC-кривые, которые представлены в файле `result.png`

Краткую презентацию по данному проекту можно посмотреть [*здесь*](https://docs.google.com/presentation/d/1oq2f3EIwXVEsWLJ-778hUvMroTci6bkQtuv9lL62eMA)